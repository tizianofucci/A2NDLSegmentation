{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass_Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5FnwOggnFIl"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOBDSA9BnFIx"
      },
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bns18Nm7oORk"
      },
      "source": [
        "cwd = os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8bhsWQnnU-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fd8261-efef-45bb-ac2b-64893b2dc963"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw-loJ73n0eS"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Development_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3gCzJ2NP3Rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26f6918-dfac-4b15-a656-4fcdff2bb6aa"
      },
      "source": [
        "cd drive/MyDrive"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH3lzlVqnFI2"
      },
      "source": [
        "# Example: Image Segmentation\n",
        "## Build segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N88wG50nFI3"
      },
      "source": [
        "import starting_kit.read_mask_example as rme\n",
        "import starting_kit.prepare_submission as ps\n",
        "import shutil\n",
        "import random\n",
        "import json\n",
        "import math\n",
        "\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  \n",
        "\n",
        "# Get current working directory\n",
        "cwd = os.path.join(os.path.dirname(os.getcwd()),\"Development_Dataset\")\n",
        "\n",
        "test_dir = {}\n",
        "dataset_dir = {}\n",
        "\n",
        "dataset_dir[0] = os.path.join(cwd,'Training/Bipbip/Mais')\n",
        "dataset_dir[1] = os.path.join(cwd,'Training/Bipbip/Haricot')\n",
        "\n",
        "test_dir[0] = os.path.join(cwd,'Test_Dev/Bipbip/Mais')\n",
        "test_dir[1] = os.path.join(cwd,'Test_Dev/Bipbip/Haricot')\n",
        "test_dir[2] = os.path.join(cwd,'Test_Dev/Pead/Mais')\n",
        "test_dir[3] = os.path.join(cwd,'Test_Dev/Pead/Haricot')\n",
        "test_dir[4] = os.path.join(cwd,'Test_Dev/Roseau/Mais')\n",
        "test_dir[5] = os.path.join(cwd,'Test_Dev/Roseau/Haricot')\n",
        "test_dir[6] = os.path.join(cwd,'Test_Dev/Weedelec/Mais')\n",
        "test_dir[7] = os.path.join(cwd,'Test_Dev/Weedelec/Haricot')\n",
        "\n",
        "crops = {}\n",
        "\n",
        "crops[0] = \"Mais\"\n",
        "crops[1] = \"Haricot\"\n",
        "\n",
        "teams = {}\n",
        "\n",
        "teams[0] = \"Bipbip\"\n",
        "teams[1] = \"Pead\"\n",
        "teams[2] = \"Roseau\"\n",
        "teams[3] = \"Weedelec\"\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHYiQhjvRgb1",
        "outputId": "9b40f653-feb3-4c1f-e1c3-0e998e7c55fc"
      },
      "source": [
        "print(dataset_dir)\r\n",
        "print(test_dir)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: '/content/drive/Development_Dataset/Training/Bipbip/Mais', 1: '/content/drive/Development_Dataset/Training/Bipbip/Haricot'}\n",
            "{0: '/content/drive/Development_Dataset/Test_Dev/Bipbip/Mais', 1: '/content/drive/Development_Dataset/Test_Dev/Bipbip/Haricot', 2: '/content/drive/Development_Dataset/Test_Dev/Pead/Mais', 3: '/content/drive/Development_Dataset/Test_Dev/Pead/Haricot', 4: '/content/drive/Development_Dataset/Test_Dev/Roseau/Mais', 5: '/content/drive/Development_Dataset/Test_Dev/Roseau/Haricot', 6: '/content/drive/Development_Dataset/Test_Dev/Weedelec/Mais', 7: '/content/drive/Development_Dataset/Test_Dev/Weedelec/Haricot'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Yg_m_hRgqo"
      },
      "source": [
        "dataset_dir = {0: '/content/Development_Dataset/Training/Bipbip/Mais', 1: '/content/Development_Dataset/Training/Bipbip/Haricot'}\r\n",
        "test_dir = {0: '/content/Development_Dataset/Test_Dev/Bipbip/Mais', 1: '/content/Development_Dataset/Test_Dev/Bipbip/Haricot', 2: '/content/Development_Dataset/Test_Dev/Pead/Mais', 3: '/content/Development_Dataset/Test_Dev/Pead/Haricot', 4: '/content/Development_Dataset/Test_Dev/Roseau/Mais', 5: '/content/Development_Dataset/Test_Dev/Roseau/Haricot', 6: '/content/Development_Dataset/Test_Dev/Weedelec/Mais', 7: '/content/Development_Dataset/Test_Dev/Weedelec/Haricot'}\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsieZk4aKhm6"
      },
      "source": [
        "# ImageDataGenerator\n",
        "# ------------------\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "apply_data_augmentation = True\n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "# We need two different generators for images and corresponding masks\n",
        "if apply_data_augmentation:\n",
        "    img_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                      width_shift_range=10,\n",
        "                                      height_shift_range=10,\n",
        "                                      zoom_range=0.3,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip=True,\n",
        "                                      fill_mode='reflect')\n",
        "    mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                       width_shift_range=10,\n",
        "                                       height_shift_range=10,\n",
        "                                       zoom_range=0.3,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       fill_mode='reflect')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrdiIh_PWjB"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(tf.keras.utils.Sequence):\n",
        "\n",
        "    \"\"\"\n",
        "        CustomDataset inheriting from tf.keras.utils.Sequence.\n",
        "\n",
        "        3 main methods:\n",
        "          - __init__: save dataset params like directory, filenames..\n",
        "          - __len__: return the total number of samples in the dataset\n",
        "          - __getitem__: return a sample from the dataset\n",
        "\n",
        "        Note: \n",
        "          - the custom dataset return a single sample from the dataset. Then, we use \n",
        "            a tf.data.Dataset object to group samples into batches.\n",
        "          - in this case we have a different structure of the dataset in memory. \n",
        "            We have all the images in the same folder and the training and validation splits\n",
        "            are defined in text files.\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
        "                preprocessing_function=None, out_shape=[256, 256]):\n",
        "        if which_subset == 'training':\n",
        "            subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
        "        elif which_subset == 'validation':\n",
        "            subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n",
        "    \n",
        "        with open(subset_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "    \n",
        "        subset_filenames = []\n",
        "        for line in lines:\n",
        "            subset_filenames.append(line.strip()) \n",
        "\n",
        "        self.which_subset = which_subset\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.subset_filenames = subset_filenames\n",
        "        self.img_generator = img_generator\n",
        "        self.mask_generator = mask_generator\n",
        "        self.preprocessing_function = preprocessing_function\n",
        "        self.out_shape = out_shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset_filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Read Image\n",
        "        curr_filename = self.subset_filenames[index]\n",
        "        img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n",
        "        #mask = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'))\n",
        "\n",
        "        # Resize image and mask\n",
        "        img = img.resize(self.out_shape)\n",
        "        \n",
        "\n",
        "        \n",
        "       # mask = mask.resize(self.out_shape)\n",
        "    \n",
        "        img_arr = np.array(img)\n",
        "        mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
        "        #print(mask_arr.shape)\n",
        "        \n",
        "        # in this dataset 255 mask label is assigned to an additional class, which corresponds \n",
        "        # to the contours of the objects. We remove it for simplicity.\n",
        "        mask_arr[mask_arr == 255] = 0  \n",
        "\n",
        "        mask_arr = np.expand_dims(mask_arr, -1)\n",
        "\n",
        "        if self.which_subset == 'training':\n",
        "            if self.img_generator is not None and self.mask_generator is not None:\n",
        "                # Perform data augmentation\n",
        "                # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
        "                # and we can apply it to the image using apply_transform\n",
        "                img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
        "                mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
        "                img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
        "                # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
        "                # Thus, when applied to the masks it will output 'interpolated classes', which\n",
        "                # is an unwanted behaviour. As a trick, we can transform each class mask \n",
        "                # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
        "                # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
        "                out_mask = np.zeros_like(mask_arr)\n",
        "                for c in np.unique(mask_arr):\n",
        "                    if c > 0:\n",
        "                        curr_class_arr = np.float32(mask_arr == c)\n",
        "                        curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
        "                        # from [0, 1] to {0, 1}\n",
        "                        curr_class_arr = np.uint8(curr_class_arr)\n",
        "                        # recover original class\n",
        "                        curr_class_arr = curr_class_arr * c \n",
        "                        out_mask += curr_class_arr\n",
        "        else:\n",
        "            out_mask = mask_arr\n",
        "    \n",
        "        if self.preprocessing_function is not None:\n",
        "            img_arr = self.preprocessing_function(img_arr)\n",
        "        \n",
        "        return img_arr, np.float32(out_mask)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usz5SKPeQrOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391f35b2-2034-41f6-adca-dafdb0d6e678"
      },
      "source": [
        "for j in range (0,2):\n",
        "    if not os.path.exists(os.path.join(dataset_dir[j],\"Splits/\")):\n",
        "        os.makedirs(os.path.join(dataset_dir[j],\"Splits/\"))\n",
        "\n",
        "    image_filenames = next(os.walk(os.path.join(dataset_dir[j],\"Images/\")))[2]\n",
        "    \n",
        "    val=[]\n",
        "    train=[]\n",
        "    \n",
        "    for image_name in image_filenames:\n",
        "        if 100*random.random() < 10:\n",
        "            val.append(image_name[:-4])\n",
        "        else:\n",
        "            train.append(image_name[:-4])\n",
        "    \n",
        "    with open(os.path.join(dataset_dir[j],\"Splits\",\"train.txt\"), 'w') as file:  # Use file to refer to the file object\n",
        "        for i in train:\n",
        "            file.write(str(i)+\"\\n\")\n",
        "    \n",
        "    with open(os.path.join(dataset_dir[j],\"Splits\",\"val.txt\"), 'w') as file:  # Use file to refer to the file object\n",
        "        for i in val:\n",
        "            file.write(str(i)+\"\\n\")\n",
        "\n",
        "   "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgpWhorBogdB"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
        "\n",
        "img_h = 1536\n",
        "img_w = 2048\n",
        "\n",
        "dataset = CustomDataset(dataset_dir[0], 'training', \n",
        "                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
        "                        preprocessing_function=preprocess_input, out_shape=[img_w,img_h])\n",
        "\n",
        "dataset1 = CustomDataset(dataset_dir[1], 'training', \n",
        "                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
        "                        preprocessing_function=preprocess_input, out_shape=[img_w,img_h])\n",
        "\n",
        "dataset_valid = CustomDataset(dataset_dir[0], 'validation', \n",
        "                              preprocessing_function=preprocess_input,out_shape=[img_w,img_h])\n",
        "\n",
        "dataset_valid1 = CustomDataset(dataset_dir[1], 'validation', \n",
        "                              preprocessing_function=preprocess_input,out_shape=[img_w,img_h])\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOBabUbmnFJE"
      },
      "source": [
        "\n",
        "train_dataset0 = tf.data.Dataset.from_generator(lambda: dataset,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "\n",
        "train_dataset1 = tf.data.Dataset.from_generator(lambda: dataset1,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "\n",
        "train_dataset = train_dataset0.concatenate(train_dataset1)\n",
        "\n",
        "train_dataset = train_dataset.batch(1)\n",
        "\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "valid_dataset0 = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "valid_dataset1 = tf.data.Dataset.from_generator(lambda: dataset_valid1,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
        "\n",
        "valid_dataset = valid_dataset0.concatenate(valid_dataset1)\n",
        "\n",
        "valid_dataset = valid_dataset.batch(1)\n",
        "\n",
        "valid_dataset = valid_dataset.repeat()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eunbPwWqPnB"
      },
      "source": [
        "# Let's test data generator\n",
        "# -------------------------\n",
        "import time\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Assign a color to each class\n",
        "evenly_spaced_interval = np.linspace(0, 1, 3)\n",
        "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
        "\n",
        "iterator = iter(valid_dataset)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "553NrJXrFCZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f4cc139-6403-408f-cfed-be5c9620ed81"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "augmented_img, target = next(iterator)\n",
        "augmented_img = augmented_img[0]   # First element\n",
        "augmented_img = augmented_img  # denormalize\n",
        "\n",
        "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
        "\n",
        "print(np.unique(target))\n",
        "\n",
        "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "target_img[np.where(target == 0)] = [0, 0, 0]\n",
        "for i in range(1, 3):\n",
        "  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
        "\n",
        "ax[0].imshow(np.uint8(augmented_img))\n",
        "ax[1].imshow(np.uint8(target_img))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2102, in execution_mode\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 758, in _next_internal\n",
            "    output_shapes=self._flat_output_shapes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2610, in iterator_get_next\n",
            "    _ops.raise_from_not_ok_status(e, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]] [Op:IteratorGetNext]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-20-9daa7a1a03e9>\", line 3, in <module>\n",
            "    augmented_img, target = next(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 736, in __next__\n",
            "    return self.next()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in next\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 764, in _next_internal\n",
            "    return structure.from_compatible_tensor_list(self._element_spec, ret)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2105, in execution_mode\n",
            "    executor_new.wait()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'InvalidArgumentError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2102, in execution_mode\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 758, in _next_internal\n",
            "    output_shapes=self._flat_output_shapes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2610, in iterator_get_next\n",
            "    _ops.raise_from_not_ok_status(e, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]] [Op:IteratorGetNext]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-20-9daa7a1a03e9>\", line 3, in <module>\n",
            "    augmented_img, target = next(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 736, in __next__\n",
            "    return self.next()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in next\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 764, in _next_internal\n",
            "    return structure.from_compatible_tensor_list(self._element_spec, ret)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2105, in execution_mode\n",
            "    executor_new.wait()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'InvalidArgumentError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1826, in showtraceback\n",
            "    value, tb, tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1411, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
            "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
            "TypeError: must be str, not list\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2102, in execution_mode\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 758, in _next_internal\n",
            "    output_shapes=self._flat_output_shapes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2610, in iterator_get_next\n",
            "    _ops.raise_from_not_ok_status(e, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6843, in raise_from_not_ok_status\n",
            "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]] [Op:IteratorGetNext]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-20-9daa7a1a03e9>\", line 3, in <module>\n",
            "    augmented_img, target = next(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 736, in __next__\n",
            "    return self.next()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in next\n",
            "    return self._next_internal()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 764, in _next_internal\n",
            "    return structure.from_compatible_tensor_list(self._element_spec, ret)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\", line 2105, in execution_mode\n",
            "    executor_new.wait()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\", line 67, in wait\n",
            "    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n",
            "    ret = func(*args)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n",
            "    values = next(generator_state.get_iterator(iterator_id))\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in __iter__\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 486, in <genexpr>\n",
            "    for item in (self[i] for i in range(len(self))):\n",
            "\n",
            "  File \"<ipython-input-13-6c21d93988da>\", line 61, in __getitem__\n",
            "    mask_arr = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'),self.out_shape)#WHAT NEEDS TO BE CHANGED\n",
            "\n",
            "TypeError: read_rgb_mask() takes 1 positional argument but 2 were given\n",
            "\n",
            "\n",
            "\t [[{{node PyFunc}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'InvalidArgumentError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2899, in run_code\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1826, in showtraceback\n",
            "    value, tb, tb_offset=tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1411, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
            "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1182, in structured_traceback\n",
            "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
            "TypeError: must be str, not list\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'InvalidArgumentError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                 \u001b[0mformatted_exceptions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not list"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1TGlOMnFJM"
      },
      "source": [
        "vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
        "vgg.summary()\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvsdiF0TFTbt"
      },
      "source": [
        "def create_model(depth, start_f, num_classes):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    # Encoder\n",
        "    # -------\n",
        "    model.add(vgg)\n",
        "    \n",
        "    start_f = 256\n",
        "        \n",
        "    # Decoder\n",
        "    # -------\n",
        "    for i in range(depth):\n",
        "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
        "                                         kernel_size=(3, 3),\n",
        "                                         strides=(1, 1),\n",
        "                                         padding='same'))\n",
        "        model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "        start_f = start_f // 2\n",
        "\n",
        "    # Prediction Layer\n",
        "    # ----------------\n",
        "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=(1, 1),\n",
        "                                     padding='same',\n",
        "                                     activation='softmax'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k97OK6CRnFJS",
        "scrolled": true
      },
      "source": [
        "model = create_model(depth=5, \n",
        "                     start_f=8, \n",
        "                     num_classes=3)\n",
        "\n",
        "# Visualize created model as a table\n",
        "model.summary()\n",
        "\n",
        "# Visualize initialized weights\n",
        "# model.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGzh16WTnFJW"
      },
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "\n",
        "# Loss\n",
        "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
        "# learning rate\n",
        "lr = 1e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# -------------------\n",
        "\n",
        "# Here we define the intersection over union for each class in the batch.\n",
        "# Then we compute the final iou as the mean over classes\n",
        "def meanIoU(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(1,3): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)\n",
        "\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "metrics = ['accuracy', meanIoU]\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MlmYGVMnFJW"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "cwd1 = os.getcwd()\n",
        "\n",
        "exps_dir = os.path.join(cwd1, 'multiclass_exps')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                   save_weights_only=True)  # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_meanIoU', patience=10, mode=\"max\")\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "\n",
        "model.fit(x=train_dataset,\n",
        "          epochs=100,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(dataset)+len(dataset1),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(dataset_valid)+len(dataset_valid1), \n",
        "          callbacks=callbacks)\n",
        "\n",
        "# How to visualize Tensorboard\n",
        "\n",
        "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
        "# 2. localhost:PORT   <- in your browser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA6D_TBknFJZ"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "iterator = iter(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XiwaKZhnFJa",
        "scrolled": true
      },
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(8, 8))\n",
        "fig.show()\n",
        "image, target = next(iterator)\n",
        "\n",
        "image = image[0]\n",
        "target = target[0, ..., 0]\n",
        "\n",
        "out_sigmoid = model.predict(x=tf.expand_dims(image, 0))\n",
        "\n",
        "# Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "# predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
        "# predicted_class = predicted_class[0, ..., 0]\n",
        "predicted_class = tf.argmax(out_sigmoid, -1)\n",
        "\n",
        "out_sigmoid.shape\n",
        "\n",
        "predicted_class = predicted_class[0, ...]\n",
        "\n",
        "# Assign colors (just for visualization)\n",
        "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "prediction_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "target_img[np.where(target == 0)] = [0, 0, 0]\n",
        "for i in range(1, 3):\n",
        "  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n",
        "\n",
        "prediction_img[np.where(predicted_class == 0)] = [0, 0, 0]\n",
        "for i in range(1, 3):\n",
        "  prediction_img[np.where(predicted_class == i)] = np.array(colors[i-1])[:3] * 255\n",
        "\n",
        "ax[0].imshow(np.uint8(image))\n",
        "ax[1].imshow(np.uint8(target_img))\n",
        "ax[2].imshow(np.uint8(prediction_img))\n",
        "\n",
        "fig.canvas.draw()\n",
        "time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ1Yl-InnFJd"
      },
      "source": [
        "submission_dict = {} \n",
        "\n",
        "for i in range(0,8):\n",
        "    image_filenames = next(os.walk(os.path.join(test_dir[i],\"Images/\")))[2]\n",
        "\n",
        "    if i in range(4,6):\n",
        "        suffix = \".png\"\n",
        "    else:\n",
        "        suffix = \".jpg\"\n",
        "    \n",
        "    print (suffix)\n",
        "    for image_name in image_filenames:\n",
        "    \n",
        "    \n",
        "        image_name=image_name[:-4]\n",
        "        img = Image.open(os.path.join(test_dir[i], 'Images', image_name + suffix))\n",
        "        #mask = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'))\n",
        "\n",
        "        # Resize image and mask\n",
        "        img = img.resize([img_w,img_h])\n",
        "        \n",
        "\n",
        "        \n",
        "        # mask = mask.resize(self.out_shape)\n",
        "    \n",
        "        img_arr = preprocess_input(np.array(img))\n",
        "    \n",
        "        # load mask <- HERE you should have your segmentation model instead\n",
        "        mask_arr = model.predict_classes(x=tf.expand_dims(img_arr, 0))\n",
        "\n",
        "    \n",
        "        submission_dict[image_name] = {}\n",
        "        submission_dict[image_name]['shape'] = [img_h,img_w]\n",
        "        submission_dict[image_name]['team'] = teams[math.floor(i/2)]\n",
        "        submission_dict[image_name]['crop'] = crops[i%2]\n",
        "        submission_dict[image_name]['segmentation'] = {}\n",
        "\n",
        "        # RLE encoding\n",
        "        # crop\n",
        "        rle_encoded_crop = ps.rle_encode(mask_arr == 1)\n",
        "        # weed\n",
        "        rle_encoded_weed = ps.rle_encode(mask_arr == 2)\n",
        "\n",
        "        submission_dict[image_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "        submission_dict[image_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "        # Please notice that in this example we have a single prediction.\n",
        "        # For the competition you have to provide segmentation for each of\n",
        "        # the test images.\n",
        "\n",
        "        # Finally, save the results into the submission.json file\n",
        "with open(os.path.join(dataset_dir[0],\"submission.json\"), 'w') as f:\n",
        "    json.dump(submission_dict, f)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuVw1q_NnFJh"
      },
      "source": [
        "image_filenames = next(os.walk(os.path.join(test_dir,\"Images/\")))[2]\n",
        "\n",
        "for image_name in image_filenames:\n",
        "    image_name=image_name[:-4]\n",
        "    img = Image.open(os.path.join(test_dir, 'Images', image_name + '.jpg'))\n",
        "    #mask = rme.read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'))\n",
        "\n",
        "    # Resize image and mask\n",
        "    img = img.resize([img_w,img_h])\n",
        "        \n",
        "\n",
        "        \n",
        "    # mask = mask.resize(self.out_shape)\n",
        "    \n",
        "    img_arr = np.array(img)\n",
        "    model.predict(x=tf.expand_dims(img_arr, 0))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JUMMkS9eyQW"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(8, 8))\n",
        "fig.show()\n",
        "\n",
        "image = Image.open(os.path.join(cwd,'Test_Dev/Bipbip/Mais/Images', 'Bipbip_mais_im_02211.jpg'))\n",
        "\n",
        "image = preprocess_input(np.array(image))\n",
        "\n",
        "\n",
        "out_sigmoid = model.predict(x=tf.expand_dims(image, 0))\n",
        "\n",
        "# Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "# predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
        "# predicted_class = predicted_class[0, ..., 0]\n",
        "predicted_class = tf.argmax(out_sigmoid, -1)\n",
        "\n",
        "out_sigmoid.shape\n",
        "\n",
        "predicted_class = predicted_class[0, ...]\n",
        "\n",
        "# Assign colors (just for visualization)\n",
        "prediction_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "\n",
        "\n",
        "prediction_img[np.where(predicted_class == 0)] = [0, 0, 0]\n",
        "for i in range(1, 3):\n",
        "  prediction_img[np.where(predicted_class == i)] = np.array(colors[i-1])[:3] * 255\n",
        "\n",
        "ax[0].imshow(np.uint8(image))\n",
        "ax[1].imshow(np.uint8(prediction_img))\n",
        "\n",
        "fig.canvas.draw()\n",
        "time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo1JbCO5nFJh",
        "scrolled": false
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M75UjH7xxS7J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}